{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burak\\AppData\\Local\\Temp\\ipykernel_16804\\2484191830.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.drop([\"Clearsky GHI\"],axis=1,inplace=True)\n",
      "C:\\Users\\burak\\AppData\\Local\\Temp\\ipykernel_16804\\2484191830.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.drop([\"Clearsky GHI\"],axis=1,inplace=True)\n",
      "C:\\Users\\burak\\AppData\\Local\\Temp\\ipykernel_16804\\2484191830.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Datetime\"] = pd.to_datetime(train[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
      "C:\\Users\\burak\\AppData\\Local\\Temp\\ipykernel_16804\\2484191830.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"Datetime\"] = pd.to_datetime(test[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
      "C:\\Users\\burak\\AppData\\Local\\Temp\\ipykernel_16804\\2484191830.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.drop([\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"],axis=1,inplace=True)\n",
      "C:\\Users\\burak\\AppData\\Local\\Temp\\ipykernel_16804\\2484191830.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.drop([\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "train_size = int(len(data) * 0.8)\n",
    "test_size = len(data) - train_size\n",
    "train, test = data.iloc[0:train_size], data.iloc[train_size:len(data)]\n",
    "Scaler = MinMaxScaler()\n",
    "train_GHI = train[\"Clearsky GHI\"].values\n",
    "train.drop([\"Clearsky GHI\"],axis=1,inplace=True)\n",
    "#train.drop(correlated_Columns,axis=1,inplace=True)\n",
    "test_GHI = test[\"Clearsky GHI\"].values\n",
    "\n",
    "test.drop([\"Clearsky GHI\"],axis=1,inplace=True)\n",
    "#test.drop(correlated_Columns,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "train[\"Datetime\"] = pd.to_datetime(train[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "test[\"Datetime\"] = pd.to_datetime(test[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "\n",
    "train.set_index(\"Datetime\",inplace=True)\n",
    "test.set_index(\"Datetime\",inplace=True)\n",
    "\n",
    "train.drop([\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"],axis=1,inplace=True)\n",
    "test.drop([\"Year\",\"Month\",\"Day\",\"Hour\",\"Minute\"],axis=1,inplace=True)\n",
    "\n",
    "train = Scaler.fit_transform(train)\n",
    "test = Scaler.fit_transform(test)\n",
    "\n",
    "train_GHI = Scaler.fit_transform(train_GHI.reshape(-1,1))\n",
    "test_GHI = Scaler.fit_transform(test_GHI.reshape(-1,1))\n",
    "\n",
    "def createSequence(data,window_size):\n",
    "    sequences = []\n",
    "    for i in range(0,len(data) - window_size +1):\n",
    "        sequence = data[i:i+window_size]\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequences_96 = createSequence(train,window_size=96) # 2 day\n",
    "\n",
    "train_GHI_96  = createSequence(train_GHI,window_size=96)\n",
    "test_GHI_96 = createSequence(test_GHI,window_size=96)\n",
    "\n",
    "\n",
    "sequences_96_tensor = torch.tensor(sequences_96).float().cuda()\n",
    "train_GHI_96_tensor = torch.tensor(train_GHI_96).float().cuda()\n",
    "test_GHI_96_tensor = torch.tensor(test_GHI_96).float().cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, lr):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=32, batch_first=True)\n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def compile(self, x, y):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss_function(output, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_data, train_labels, test_data, test_labels, epochs, batch_size):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            x = train_data[i:i + batch_size]\n",
    "            y = train_labels[i:i + batch_size]\n",
    "            loss = model.compile(x, y)\n",
    "            train_loss.append(loss)\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_data), batch_size):\n",
    "                x = test_data[i:i + batch_size]\n",
    "                y = test_labels[i:i + batch_size]\n",
    "                pred = model.forward(x)\n",
    "                loss = model.loss_function(pred, y)\n",
    "                test_loss.append(loss.item())\n",
    "        print(\"Epoch: {}, Train Loss: {}, Test Loss: {}\".format(epoch+1, train_loss[-1], test_loss[-1]))\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.5521791283390485e-05, Test Loss: 0.00025400909362360835\n",
      "Epoch: 2, Train Loss: 6.147182375570992e-06, Test Loss: 0.00020034764020238072\n",
      "Epoch: 3, Train Loss: 4.913292286801152e-06, Test Loss: 0.00019949831767007709\n",
      "Epoch: 4, Train Loss: 3.333005679451162e-06, Test Loss: 0.00020945396681781858\n",
      "Epoch: 5, Train Loss: 1.9532681108103134e-06, Test Loss: 0.00022133874881546944\n",
      "Epoch: 6, Train Loss: 1.3612310567623354e-06, Test Loss: 0.00022364759934134781\n",
      "Epoch: 7, Train Loss: 9.92446416603343e-07, Test Loss: 0.00023309812240768224\n",
      "Epoch: 8, Train Loss: 7.295098498616426e-07, Test Loss: 0.0002447334991302341\n",
      "Epoch: 9, Train Loss: 5.614995757241559e-07, Test Loss: 0.0002518611145205796\n",
      "Epoch: 10, Train Loss: 4.2791435816980083e-07, Test Loss: 0.00025733516667969525\n",
      "Epoch: 11, Train Loss: 3.7642951156158233e-07, Test Loss: 0.00026021338999271393\n",
      "Epoch: 12, Train Loss: 5.095790811537881e-07, Test Loss: 0.0002741360804066062\n",
      "Epoch: 13, Train Loss: 3.1628815122530796e-07, Test Loss: 0.0002610214869491756\n",
      "Epoch: 14, Train Loss: 2.710947342166037e-07, Test Loss: 0.0002705351507756859\n",
      "Epoch: 15, Train Loss: 2.779753742743196e-07, Test Loss: 0.0002730448613874614\n",
      "Epoch: 16, Train Loss: 2.654067543517158e-07, Test Loss: 0.0002797093184199184\n",
      "Epoch: 17, Train Loss: 2.9957203651065356e-07, Test Loss: 0.0002758848713710904\n",
      "Epoch: 18, Train Loss: 2.6550412712822435e-07, Test Loss: 0.0002758369082584977\n",
      "Epoch: 19, Train Loss: 2.6212106263301393e-07, Test Loss: 0.0002807199489325285\n",
      "Epoch: 20, Train Loss: 2.7808067670775927e-07, Test Loss: 0.000279852218227461\n"
     ]
    }
   ],
   "source": [
    "test_sequences_96_tensor = torch.tensor(createSequence(test,window_size=96)).float().cuda()\n",
    "model = Model(lr=0.001).cuda()\n",
    "train_loss, test_loss = train_model(model, sequences_96_tensor, train_GHI_96_tensor, test_sequences_96_tensor, test_GHI_96_tensor, 20, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model on  local\n",
    "torch.save(model.state_dict(), \"lstm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
